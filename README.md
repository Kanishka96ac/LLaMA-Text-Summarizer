# LLaMA Text Summarizer â€“ Local AI Summarization Tool

The **LLaMA Text Summarizer** is a privacy-first AI tool that summarises large bodies of text **entirely on your local machine** using [Ollama](https://ollama.com) and the LLaMA language model.

Built with **FastAPI** (backend) and **Streamlit** (frontend), it provides a clean web interface for quick and accurate summaries without sending your data to the cloud.

---

## ğŸš€ Features

- **FastAPI Backend** â€“ Handles summarisation requests and communicates with Ollama.
- **Streamlit Frontend** â€“ Interactive, easy-to-use web interface.
- **Local AI Processing** â€“ All summaries generated locally for maximum privacy.
- **Customisation** â€“ Choose model, temperature, and max token count.
- **Downloadable Summaries** â€“ Save the results as `.txt` files.
- **Two-Part Setup** â€“ Backend and frontend run independently.

---

## ğŸ›  Tech Stack

- **Backend:** FastAPI, Uvicorn, Requests, Python Multipart
- **Frontend:** Streamlit
- **AI Model:** LLaMA via Ollama
- **Language:** Python 3.10+

---

## ğŸ“‚ Project Structure

```
Text_Summarizer/
â”‚â”€â”€ backend/
â”‚   â””â”€â”€ main.py         # FastAPI backend
â”‚â”€â”€ frontend/
â”‚   â””â”€â”€ app.py          # Streamlit frontend
â”‚â”€â”€ scripts/
â”‚   â””â”€â”€ start.sh        # Optional startup script
â”‚â”€â”€ requirements.txt    # Python dependencies
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
â”‚â”€â”€ venv/               # Virtual environment
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Install Ollama

Download and install Ollama:  
[https://ollama.com/download](https://ollama.com/download)

Pull the LLaMA model:

```bash
ollama pull llama2
```

### 2ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/llama-text-summarizer.git
cd llama-text-summarizer
```

### 3ï¸âƒ£ Create & activate virtual environment

```bash
python -m venv venv

# Windows (PowerShell)
.\venv\Scripts\Activate.ps1

# macOS/Linux
source venv/bin/activate
```

### 4ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the App

**Step 1 â€“ Start backend (FastAPI)**

```bash
uvicorn backend.main:app --reload
```

Backend runs at: `http://localhost:8000`

**Step 2 â€“ Start frontend (Streamlit)**

```bash
streamlit run frontend/app.py
```

Frontend opens in your browser at: `http://localhost:8501`

---

## ğŸ§ª Example Usage

1. Paste or type text into the text area.
2. Adjust **model**, **temperature**, and **max tokens** from the sidebar.
3. Click **Summarize**.
4. Download the summary as `.txt`.

---

## ğŸ”® Future Improvements

- PDF / DOCX file upload & summarisation.
- Chunking long documents and combining results.
- Support for multiple models (Mistral, Gemma, etc.).
- Real-time streaming summaries.

---

## ğŸ”— Connect with Me

ğŸ“§ kanishka96se@gmail.com  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/kanishka96/) | [GitHub](https://github.com/Kanishka96ac)
